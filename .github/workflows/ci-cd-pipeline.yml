name: 🔬 Advanced Compensation Research CI/CD Pipeline

permissions:
  contents: write
  actions: read
  checks: write

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Production: Every 10 minutes
    - cron: '*/10 * * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      run_tests:
        description: 'Run full test suite'
        required: false
        default: true
        type: boolean
      force_research_cycle:
        description: 'Force research cycle even if no new papers'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  CACHE_VERSION: v1

jobs:
  # =================== QUALITY ASSURANCE ===================
  quality-checks:
    name: 🔍 Quality Assurance
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'pull_request'

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        persist-credentials: true
        fetch-depth: 0

    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Cache Dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/pip
          .pytest_cache
        key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-

    - name: 🔧 Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: 🔒 Security Scan
      run: |
        pip install bandit safety
        bandit -r . -f json -o bandit-report.json || true
        safety check --json --output safety-report.json || true

    - name: 📊 Code Quality Analysis
      run: |
        pip install flake8 black isort mypy
        black --check . || true
        isort --check-only . || true
        flake8 . --count --statistics --output-file=flake8-report.txt || true
        mypy . --ignore-missing-imports --no-strict-optional || true

    - name: 🧪 Run Unit Tests
      run: |
        pip install pytest pytest-cov pytest-html
        pytest tests/ --cov=. --cov-report=xml --cov-report=html --html=test-report.html --self-contained-html

    - name: 📈 Upload Coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false

    - name: 📋 Upload Test Reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: quality-reports
        path: |
          bandit-report.json
          safety-report.json
          flake8-report.txt
          test-report.html
          htmlcov/
        include-hidden-files: true

  # =================== INTEGRATION TESTS ===================
  integration-tests:
    name: 🔗 Integration Tests
    runs-on: ubuntu-latest
    needs: quality-checks
    if: github.event.inputs.run_tests == 'true' || github.event.inputs.run_tests == ''

    strategy:
      matrix:
        test-suite: ['paper-screening', 'why-analysis', 'node-connection', 'obsidian-generation', 'full-system']

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        persist-credentials: true

    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Restore Cache
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements*.txt') }}

    - name: 🔧 Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: 🧪 Run Integration Tests
      env:
        TEST_SUITE: ${{ matrix.test-suite }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python -m pytest tests/integration/test_${{ matrix.test-suite }}.py -v --tb=short

    - name: 📊 Upload Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results-${{ matrix.test-suite }}
        path: test-results/

  # =================== RESEARCH AUTOMATION ===================
  research-automation:
    name: 🔬 Research Automation
    runs-on: ubuntu-latest
    needs: [quality-checks]
    if: |
      (github.event_name == 'schedule') ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'production') ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main')

    environment:
      name: ${{ github.event.inputs.environment || 'production' }}
      url: ${{ steps.deploy.outputs.vault-url }}

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.RESEARCH_TOKEN || secrets.GITHUB_TOKEN }}
        persist-credentials: true

    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Restore Cache
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/pip
          .research_cache/
        key: ${{ runner.os }}-research-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements*.txt') }}

    - name: 🔧 Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: 🔍 Pre-Research Health Check
      id: health_check
      run: |
        python scripts/health_check.py
        echo "status=$(cat health_status.txt)" >> $GITHUB_OUTPUT

    - name: 🔬 Execute Research Cycle
      id: research
      env:
        ENVIRONMENT: ${{ github.event.inputs.environment || 'production' }}
        FORCE_CYCLE: ${{ github.event.inputs.force_research_cycle || 'false' }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        RESEARCH_CONFIG: ${{ secrets.RESEARCH_CONFIG }}
      run: |
        python compensation_research_system.py --mode=production --environment=$ENVIRONMENT
        echo "papers_processed=$(cat research_output/papers_count.txt)" >> $GITHUB_OUTPUT
        echo "patterns_discovered=$(cat research_output/patterns_count.txt)" >> $GITHUB_OUTPUT
        echo "vault_size=$(du -sh Compensation-Research-Vault/ | cut -f1)" >> $GITHUB_OUTPUT

    - name: 📊 Research Metrics Collection
      run: |
        python scripts/collect_metrics.py
        cat research_metrics.json

    - name: 🔄 Git Configuration
      run: |
        git config --local user.name "github-actions[bot]"
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"

    - name: 💾 Commit Research Updates
      id: commit
      run: |
        git add -A
        if [ -n "$(git status --porcelain)" ]; then
          git commit -m "🔬 Research Update - $(date '+%Y-%m-%d %H:%M UTC')

          📊 Cycle Summary:
          - Papers Processed: ${{ steps.research.outputs.papers_processed }}
          - New Patterns: ${{ steps.research.outputs.patterns_discovered }}
          - Vault Size: ${{ steps.research.outputs.vault_size }}

          🤖 Automated via GitHub Actions [skip ci]
          Co-Authored-By: Claude <noreply@anthropic.com>"

          git pull --rebase origin "${{ github.ref_name }}" || true
          git push origin HEAD:"${{ github.ref_name }}"
          echo "changes=true" >> $GITHUB_OUTPUT
          echo "commit_hash=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT
        else
          echo "changes=false" >> $GITHUB_OUTPUT
          echo "No new research updates to commit"
        fi

    - name: 🗜️ Create Vault Backup
      if: steps.commit.outputs.changes == 'true'
      run: |
        tar -czf "vault-backup-$(date +%Y%m%d-%H%M).tar.gz" Compensation-Research-Vault/
        zip -r "vault-obsidian-$(date +%Y%m%d-%H%M).zip" Compensation-Research-Vault/

    - name: 📤 Upload Vault Artifacts
      uses: actions/upload-artifact@v4
      if: steps.commit.outputs.changes == 'true'
      with:
        name: compensation-vault-${{ github.run_number }}
        path: |
          vault-backup-*.tar.gz
          vault-obsidian-*.zip
          research_metrics.json
        retention-days: 90
        include-hidden-files: true

    - name: 🚀 Deploy to Research Portal
      id: deploy
      if: steps.commit.outputs.changes == 'true'
      run: |
        python scripts/deploy_vault.py
        echo "vault-url=https://research.compensation.ai/vault/${{ github.run_number }}" >> $GITHUB_OUTPUT

    - name: 📢 Post-Research Notifications
      if: always()
      uses: ./.github/actions/notify
      with:
        status: ${{ job.status }}
        papers_processed: ${{ steps.research.outputs.papers_processed }}
        patterns_discovered: ${{ steps.research.outputs.patterns_discovered }}
        vault_size: ${{ steps.research.outputs.vault_size }}
        commit_hash: ${{ steps.commit.outputs.commit_hash }}
        slack_webhook: ${{ secrets.SLACK_WEBHOOK }}
        discord_webhook: ${{ secrets.DISCORD_WEBHOOK }}

  # =================== PERFORMANCE MONITORING ===================
  performance-monitoring:
    name: 📊 Performance Monitoring
    runs-on: ubuntu-latest
    needs: research-automation
    if: always()

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        persist-credentials: true

    - name: 📈 Collect Performance Metrics
      env:
        MONITORING_API_KEY: ${{ secrets.MONITORING_API_KEY }}
      run: |
        python scripts/performance_monitor.py
        python scripts/cost_analysis.py

    - name: 🎯 Update Performance Dashboard
      run: |
        python scripts/update_dashboard.py

    - name: 🚨 Performance Alerts
      if: needs.research-automation.result == 'failure'
      run: |
        python scripts/alert_system.py --type=performance_degradation

  # =================== BACKUP AND RECOVERY ===================
  backup-strategy:
    name: 💾 Backup & Recovery
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' && github.event.schedule == '0 0 * * *'  # Daily at midnight

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        persist-credentials: true

    - name: 🗄️ Create Full System Backup
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        BACKUP_BUCKET: ${{ secrets.BACKUP_BUCKET }}
      run: |
        python scripts/full_backup.py
        aws s3 sync ./backups/ s3://$BACKUP_BUCKET/compensation-research/$(date +%Y%m%d)/

    - name: 🧪 Test Backup Integrity
      run: |
        python scripts/test_backup_integrity.py

    - name: 🧹 Cleanup Old Backups
      run: |
        python scripts/cleanup_backups.py --keep-days=30

  # =================== SECURITY MONITORING ===================
  security-monitoring:
    name: 🔒 Security Monitoring
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        persist-credentials: true

    - name: 🔍 Dependency Vulnerability Scan
      run: |
        pip install safety
        safety check --json --output vulnerability-report.json

    - name: 🛡️ Secrets Scanning
      uses: trufflesecurity/trufflehog@main
      with:
        path: ./
        base: main
        head: HEAD

    - name: 🚨 Security Alerts
      if: failure()
      run: |
        python scripts/security_alert.py

# =================== WORKFLOW OUTPUTS ===================
outputs:
  research_status:
    description: "Research cycle execution status"
    value: ${{ jobs.research-automation.result }}
  papers_processed:
    description: "Number of papers processed in this cycle"
    value: ${{ jobs.research-automation.outputs.papers_processed }}
  vault_url:
    description: "URL to the updated research vault"
    value: ${{ jobs.research-automation.outputs.vault-url }}